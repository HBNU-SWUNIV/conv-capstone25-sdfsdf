# íŒŒì¼ëª…: 1_ğŸ“_AI_í•™ì—…_ì¡°êµ_ì±—ë´‡.py (ìµœì¢… ê°„ê²° ë²„ì „)

import streamlit as st
import time
from collections import defaultdict
import pandas as pd

# --- í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸ (RAG/OCR ê´€ë ¨ ëª¨ë‘ ì œê±°) ---
from langchain_community.llms import Ollama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from db_utils import authenticate_student, get_student_enrollments
from academic_advisor import analyze_graduation_progress, suggest_courses

# --- ì„¤ì • ---
LLM_MODEL = "gemma3:12b"

# --- Streamlit ìºì‹±: LLM ëª¨ë¸ ë¡œë”© ---
@st.cache_resource
def load_llm():
    """LLM ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        llm = Ollama(model=LLM_MODEL)
        llm.invoke("test") # ê°„ë‹¨í•œ í˜¸ì¶œë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
        print("LLM ëª¨ë¸ ë¡œë”© ì„±ê³µ.")
        return llm
    except Exception as e:
        st.error(f"LLM ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.info("Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

# --- ë¶„ì„ ê²°ê³¼ë¥¼ LLM í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ---
def format_report_for_llm(student_name, analysis, suggestions):
    """ë¶„ì„ ë° ì¶”ì²œ ê²°ê³¼ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì¢‹ì€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    report = f"--- {student_name}ë‹˜ í•™ì—… ë¶„ì„ ë³´ê³ ì„œ ---\n\n"
    summary = analysis['summary']
    report += f"**[ì¡¸ì—…ê¹Œì§€ ë‚¨ì€ í•™ì ]**\n- ì´ í•„ìš” í•™ì : {summary['total_required']} / í˜„ì¬ ì´ìˆ˜ í•™ì : {summary['total_completed']} (ë‚¨ì€ í•™ì : {summary['total_missing']})\n"
    
    missing_areas = [area for area in analysis['by_classification'] if area['missing'] > 0]
    if not missing_areas:
        report += "\n**[ì˜ì—­ë³„ ì´ìˆ˜ í˜„í™©]**\n- ëª¨ë“  ì˜ì—­ë³„ ìµœì†Œ í•™ì ì„ ì¶©ì¡±í–ˆìŠµë‹ˆë‹¤.\n"
    else:
        report += "\n**[ë¶€ì¡±í•œ ì˜ì—­ë³„ í•™ì ]**\n"
        for area in missing_areas:
            report += f"- {area['classification']}: {area['missing']}í•™ì  ë¶€ì¡±\n"

    if analysis.get('detailed_analysis'):
        report += "\n**[ì„¸ë¶€ ì¡¸ì—…ìš”ê±´ ì¶©ì¡± í˜„í™©]**\n"
        for detail in analysis['detailed_analysis']:
            status = "âœ… ì¶©ì¡±" if detail['is_satisfied'] else "âŒ ë¯¸ì¶©ì¡±"
            report += f"- **{detail['name']}**: {status}\n"
            if not detail['is_satisfied']:
                report += f"  - ë‚´ìš©: {detail['description']}\n"
                if detail.get('missing_items'):
                    report += f"  - **ë¯¸ì´ìˆ˜ ê³¼ëª©:** {', '.join(detail['missing_items'])}\n"
                if detail.get('missing_areas'):
                    report += f"  - **ë‚¨ì€ ì˜ì—­:** {', '.join(detail['missing_areas'])}\n"
                if detail.get('details'):
                     report += f"  - í˜„í™©: {detail['details']}\n"

    if analysis['missing_required_courses']:
        report += "\n**[ì•„ì§ ë“£ì§€ ì•Šì€ í•„ìˆ˜ ê³¼ëª© ëª©ë¡ (ì „ê³µ/ëŒ€í•™íŠ¹í™”)]**\n"
        for course in analysis['missing_required_courses']:
            report += f"- {course}\n"
    
    report += "\n--- ë‹¤ìŒ í•™ê¸° ì¶”ì²œ ê³¼ëª© ëª©ë¡ (ì‹¤ì œ ê°œì„¤ ê³¼ëª© ê¸°ë°˜) ---\n"
    if not suggestions:
        report += "í˜„ì¬ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ê°œì„¤ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\n"
    else:
        for category, courses in suggestions.items():
            report += f"\n**[{category}]**\n"
            if not courses:
                report += "- ì¶”ì²œí•  ê°œì„¤ ê³¼ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
            for course in courses:
                credits = f" ({int(course['credits'])}í•™ì )" if course.get('credits') is not None else ""
                report += f"- {course['course_name']}{credits}\n"
                
    return report

# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ---
def main():
    st.set_page_config(page_title="AI í•™ì—… ì¡°êµ ì±—ë´‡", page_icon="ğŸ“", layout="wide")
    st.title("ğŸ“ AI í•™ì—… ì¡°êµ ì±—ë´‡")

    llm = load_llm()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.clear()
        st.session_state.messages = []
        st.session_state.authenticated = False
        st.session_state.student_info = None

    # --- 1. í•™ìƒ ì¸ì¦ UI ---
    if not st.session_state.authenticated:
        st.subheader("í•™ìƒ ì¸ì¦")
        with st.form("auth_form"):
            student_id = st.text_input("í•™ë²ˆ", value="20231081")
            student_name = st.text_input("ì´ë¦„", value="í•œì¬ì›…")
            submitted = st.form_submit_button("ì¸ì¦í•˜ê¸°")

            if submitted:
                if not llm:
                    st.error("ì±—ë´‡ ì‹œìŠ¤í…œì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Ollama ì„œë²„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                else:
                    student_info = authenticate_student(student_id, student_name)
                    if student_info:
                        st.session_state.authenticated = True
                        st.session_state.student_info = student_info
                        st.session_state.messages.append({"role": "assistant", "content": f"**{student_name}**ë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"})
                        st.rerun()
                    else:
                        st.error("í•™ë²ˆ ë˜ëŠ” ì´ë¦„ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        # --- 2. ì±—ë´‡ UI ---
        st.sidebar.header(f"ğŸ‘‹ {st.session_state.student_info['student_name']}ë‹˜")
        st.sidebar.markdown(f"**í•™ë²ˆ:** {st.session_state.student_info['student_id']}")
        st.sidebar.markdown(f"**í•™ê³¼:** {st.session_state.student_info['department_major']}")
        if st.sidebar.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True, type="primary"):
            st.session_state.clear()
            st.rerun()

        # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                response_container = st.empty()
                
                # RAG ê¸°ëŠ¥ì´ ì—†ìœ¼ë¯€ë¡œ, ëª¨ë“  ì§ˆë¬¸ì„ ì¡¸ì—…ìš”ê±´ ë¶„ì„ìœ¼ë¡œ ì²˜ë¦¬
                with st.spinner("í•™ì—… í˜„í™© ë¶„ì„ ë° ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    analysis = analyze_graduation_progress(st.session_state.student_info)
                    suggestions = suggest_courses(st.session_state.student_info, analysis)
                    report_for_llm = format_report_for_llm(st.session_state.student_info['student_name'], analysis, suggestions)

                    advisor_prompt = ChatPromptTemplate.from_template(
                        """ë‹¹ì‹ ì€ ëŒ€í•™êµì˜ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI í•™ì—… ì¡°êµì…ë‹ˆë‹¤.
                        ì•„ë˜ì— ì£¼ì–´ì§„ í•™ìƒì˜ 'í•™ì—… ë¶„ì„ ë° ì¶”ì²œ ë¦¬í¬íŠ¸'ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
                        ë¨¼ì €, í•™ìƒì˜ í˜„ì¬ í•™ì  í˜„í™©(ì´í•™ì , ë¶€ì¡±í•œ ì˜ì—­)ì„ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                        ê·¸ ë‹¤ìŒ, ë¦¬í¬íŠ¸ì— ìˆëŠ” 'ì„¸ë¶€ ì¡¸ì—…ìš”ê±´ ì¶©ì¡± í˜„í™©'ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì´ ë†“ì¹˜ê³  ìˆëŠ” ì¤‘ìš”í•œ ê·œì¹™ì´ ìˆë‹¤ë©´ ê°•ì¡°í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                        ë§ˆì§€ë§‰ìœ¼ë¡œ 'ë‹¤ìŒ í•™ê¸° ì¶”ì²œ ê³¼ëª© ëª©ë¡'ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ë©°, ì™œ ì´ ê³¼ëª©ë“¤ì„ ë“¤ì–´ì•¼ í•˜ëŠ”ì§€ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³  ê²©ë ¤í•˜ë©° ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.
                        
                        --- í•™ì—… ë¶„ì„ ë° ì¶”ì²œ ë¦¬í¬íŠ¸ ---
                        {report}
                        --------------------------------
                        
                        ì´ì œ ìœ„ ë¦¬í¬íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
                    )
                    advisor_chain = advisor_prompt | llm | StrOutputParser()
                    stream = advisor_chain.stream({"report": report_for_llm})
                
                full_response = "".join(list(stream))
                response_container.markdown(full_response)
                
            st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()
# python rag_setup.py
# streamlit run app.py        